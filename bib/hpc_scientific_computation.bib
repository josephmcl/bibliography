@article{balay1998petsc, 
    Author = {Satish Balay and William~D. Gropp and Lois Curfman 
        McInnes and Barry~F. Smith},
    Title = {Efficient Management of Parallelism in Object Oriented 
        Numerical Software Libraries},
    Abstract = {Parallel numerical software based on the message 
        passing model is enormously complicated. This paper introduces 
        a set of techniques to manage the complexity, while maintaining 
        high efficiency and ease of use. The PETSc 2.0 package uses 
        object-oriented programming to conceal the details of the 
        message passing, without concealing the parallelism, in a 
        high-quality set of numerical software libraries. In fact, the 
        programming model used by PETSc is also the most appropriate 
        for NUMA shared-memory machines, since they require the same 
        careful attention to memory hierarchies as do 
        distributed-memory machines. Thus, the concepts discussed are 
        appropriate for all scalable computing systems. The PETSc 
        libraries provide many of the data structures and numerical 
        kernels required for the scalable solution of PDEs, offering 
        performance portability.},
    BookTitle = {Modern Software Tools in Scientific Computing},
    Editor = {E. Arge and A.~M. Bruaset and H.~P. Langtangen},
    Publisher = {Birkh{\"{a}}user Press},
    Pages = {163--202},
    Year = {1997}}

@MISC{gael2010eigen,
    Author = {Ga\"{e}l Guennebaud and Beno\^{i}t Jacob and others},
    Title = {Eigen v3},
    HowPublished = {http://eigen.tuxfamily.org},
    Year = {2010}}

@article{qian2013blas,
    Title = {AUGEM: Automatically Generate High Performance Dense 
        Linear Algebra Kernels on x86 CPUs},
    Abstract = {Basic Liner algebra subprograms (BLAS) is a fundamental 
    library in scientific computing. In this paper, we present a 
    template-based optimization framework, AUGEM, which can 
    automatically generate fully optimized assembly code for several 
    dense linear algebra (DLA) kernels, such as GEMM, GEMV, AXPY and 
    DOT, on varying multi-core CPUs without requiring any manual 
    interference from developers. In particular, based on 
    domain-specific knowledge about algorithms of the DLA kernels, we 
    use a collection of parameter- ized code templates to formulate a 
    number of commonly oc- curring instruction sequences within the 
    optimized low-level C code of these DLA kernels. Then, our 
    framework uses a specialized low-level C optimizer to identify 
    instruction sequences that match the pre-defined code templates 
    and thereby translates them into extremely efficient SSE/AVX 
    instructions. The DLA kernels generated by our template-based 
    approach surpass the implementations of Intel MKL and AMD ACML 
    BLAS libraries, on both Intel Sandy Bridge and AMD Piledriver 
    processors.},
    Author = {Wang Qian, Zhang Xianyi, Zhang Yunquan, Qing Yi},
    Location = {Denver CO},
    Year = {2013},
    Publisher = {},
    BookTitle = {In the International Conference for High Performance 
        Computing, Networking, Storage and Analysis},
    Publisher = {Association for Computing Machinery},
    Series = {SC '13}}